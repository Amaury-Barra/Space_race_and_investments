{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook does scrape the investment data of companies that are in the space sectors.\n",
    "\n",
    "### It takes :\n",
    "#### the date of investment\n",
    "#### The amount invested (and translate it ito dollars)\n",
    "#### The investors involved in the fundrising\n",
    "#### The type of fundrising (seed, A, B, C, IPO, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "libraries loaded\n",
      "Scrapping libraries imported\n",
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import randint\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import datetime\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "## Used for google and linkedin part\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "print('libraries loaded')\n",
    "\n",
    "## Used for scraping\n",
    "import bs4\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "print('Scrapping libraries imported')\n",
    "\n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('C:/passto/dataset.xlsx',\n",
    "                encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cape analytics', 'DISH network', 'Swift Navigation']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "companies = df['Organization Name'].tolist()\n",
    "companies_test = companies[0:3]\n",
    "companies_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating location\n",
    "Returns the country of the company as we are not interested at the city or region (aggregate for EU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = df['Headquarters Location'].tolist()\n",
    "country_clean = []\n",
    "for item in location:\n",
    "    if type(item) != 'str':\n",
    "        item=str(item)\n",
    "        country_clean.append(item)\n",
    "    else:\n",
    "        country_clean.append(item)\n",
    "country_agg = []\n",
    "for item in country_clean:\n",
    "    if 'China' in item:\n",
    "        country_agg.append('China')\n",
    "    elif 'Russian Federation' in item:\n",
    "        country_agg.append('Russia')\n",
    "    elif 'United States' in item:\n",
    "        country_agg.append('USA')\n",
    "    elif 'India' in item:\n",
    "        country_agg.append('India')\n",
    "    elif 'Japan' in item:\n",
    "        country_agg.append('Japan')\n",
    "    elif 'France' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'United Kingdom' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Italy' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Spain' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Spain' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Luxembourg' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Switzerland' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Poland' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Germany' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Ireland' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Finland' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Denmark' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Sweden' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Norway' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Czech Republic' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Estonia' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Latvia' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Netherlands' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Belgium' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Bulgaria' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Croatia' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Hungary' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Greece' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Slovenia' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Portugal' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Austria' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Slovakia' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif 'Lithuania' in item:\n",
    "        country_agg.append('EU')\n",
    "    elif item=='nan':\n",
    "        country_agg.append('Unknown')\n",
    "    else:\n",
    "        country_agg.append('ROW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['USA', 'USA', 'USA']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_agg_test = country_agg[0:3]\n",
    "country_agg_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label = df['Label'].tolist()\n",
    "Label_test = Label[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the country (aggregated by world great regions) to the initial dataset\n",
    "df['country'] = country_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to excel\n",
    "df.to_excel('C:/yourway/df_compagnies.xlsx', index=None, header= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function used during scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating_dates(df):\n",
    "    '''A function that allow to keep only the year of investment as we are not\n",
    "    interested to the month/day of investment'''\n",
    "    \n",
    "    announced = df['Announced Date']\n",
    "    Announced_date=[]\n",
    "    for date in announced:\n",
    "        date = date.split(', ')[1]\n",
    "        Announced_date.append(date)\n",
    "    df['Announced_date'] = Announced_date\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doublon_missing_val_handling(df):\n",
    "    '''A function that encode string - signs as missing values and\n",
    "    discard duplicate values'''\n",
    "    \n",
    "    df['Money Raised'] = df['Money Raised'].replace({'—': np.nan})\n",
    "    df = df[~((df[['Announced_date']].duplicated(keep=False)) & (df.isnull().any(axis=1)))]\n",
    "    df = df.replace(np.nan, '—', regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversion (currency,item):\n",
    "    '''A function that translate the investment values into US dollars'''\n",
    "    \n",
    "    if currency =='$':\n",
    "        item = item*1\n",
    "    elif currency == \"A$\":\n",
    "        item = item*0.78\n",
    "    elif currency =='CA$':\n",
    "        item = item*0.79\n",
    "    elif currency == 'CN¥':\n",
    "        item = item*0.15\n",
    "    elif currency == '€':\n",
    "        item = item*1.22\n",
    "    elif currency == '£':\n",
    "        item = item*  1.37\n",
    "    elif currency == '₹':\n",
    "        item = item*0.014\n",
    "    elif currency == '¥':\n",
    "        item = item*0.0097\n",
    "    elif currency == 'NZ$':\n",
    "        item = item*0.72\n",
    "    elif currency == 'SGD':\n",
    "        item = item*0.76\n",
    "    elif currency == 'R$':\n",
    "        item = item*0.18\n",
    "    elif currency == 'CHF':\n",
    "        item = item*1.1\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating(item):\n",
    "    '''A function that convert K, M, B to the right amount of 0 to make it suitable for passage to integers'''\n",
    "    if 'M' in item:\n",
    "        item = item.replace('M','000000')\n",
    "        if '.' in item:\n",
    "            item = item.replace('.','')\n",
    "            item = item[:-1]\n",
    "        item = int(item)\n",
    "    elif 'K' in item:\n",
    "        item = item.replace('K','000')\n",
    "        if '.' in item:\n",
    "            item = item.replace('.','')\n",
    "            item = item[:-1]\n",
    "        item = int(item)\n",
    "    elif 'B' in item:\n",
    "        item = item.replace('B', '000000000')\n",
    "        if '.' in item:\n",
    "            item = item.replace('.','')\n",
    "            item = item[:-1]\n",
    "        item = int(item)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_dataset(df):\n",
    "    '''A function that discard the currency sign and convert the amount from string to integer'''\n",
    "    \n",
    "    df['Announced Date'] = pd.to_datetime(df['Announced Date']).dt.strftime('%Y')\n",
    "    money = df['Money Raised'].tolist()\n",
    "    dates = df['Announced Date'].tolist()\n",
    "   \n",
    "    money_invested=[]\n",
    "    for item in money:\n",
    "        if '—' in item:\n",
    "            item = item.replace('—', 'NaN')\n",
    "        elif '$' in item:\n",
    "            if item[0]=='A':\n",
    "                item = item[2:]\n",
    "                currency = 'A$'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif item[0]=='C':\n",
    "                item = item[3:]\n",
    "                currency = 'CA$'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif item[0] == 'N':\n",
    "                item = item[3:]\n",
    "                currency = 'NZ$'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif item[0] == '$':\n",
    "                item = item[1:]\n",
    "                currency = '$'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif item[0]=='R':\n",
    "                item = item[2:]\n",
    "                currency = 'R$'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "        elif '¥' in item:\n",
    "            if item[0]=='C':\n",
    "                item = item[3:]\n",
    "                currency = 'CN¥'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            else:\n",
    "                item = item[1:]\n",
    "                currency = '¥'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "        else:\n",
    "            if '€' in item:\n",
    "                item = item[1:]\n",
    "                currency = '€'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif '£' in item:\n",
    "                item = item[1:]\n",
    "                currency = '£'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif '₹' in item:\n",
    "                item = item[1:]\n",
    "                currency = '₹'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif 'S' in item:\n",
    "                item = item[3:]\n",
    "                currency = 'SGD'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "            elif 'CHF' in item:\n",
    "                item = item[3:]\n",
    "                currency = 'CHF'\n",
    "                item = formating(item)\n",
    "                item = conversion(currency, item)\n",
    "        money_invested.append(item)\n",
    "    df['Money'] = money_invested\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to webdriver to start the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('C:/yourway/chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.crunchbase.com/logout')\n",
    "\n",
    "username = driver.find_element_by_name('email')\n",
    "username.send_keys('your_username')\n",
    "sleep(randint(5,7))\n",
    "\n",
    "password = driver.find_element_by_name('password')\n",
    "password.send_keys('your password')\n",
    "sleep(randint(2,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "########## Initiate emplty lists to receive the scraping outcome #########################################################\n",
    "list_df_comp = [] ###### Will receive the data of investments made for each companies\n",
    "list_df_investors = [] ######## Will receive the list of investors within each companies\n",
    "list_df_investments_made = [] ##### Will receive the investment made by each companies\n",
    "list_acquisitions = []######## Will receive the acquisition  of each companies \n",
    "i=0\n",
    "while i<len(companies):\n",
    "    \n",
    "    ########################################################################\n",
    "    ############## Get the search bar and type the name of the company #####\n",
    "    search_bar = driver.find_element_by_id('mat-input-0')\n",
    "    search_bar.clear()\n",
    "    search_bar.send_keys(companies[i])\n",
    "    sleep(randint(3,4))\n",
    "    search_bar.send_keys(Keys.ENTER)\n",
    "    sleep(randint(5,8))\n",
    "    nb_result = driver.find_elements_by_class_name('component--results-info')\n",
    "    #############################################################################\n",
    "    #############################################################################\n",
    "    \n",
    "    ##############################################################################\n",
    "    ########## Start Get into company's profile ##################################\n",
    "    ##############################################################################\n",
    "    \n",
    "    \n",
    "    ############## Check the number of results for the company name after ########\n",
    "    \n",
    "    if 'PREV' in nb_result[1].text:\n",
    "        b = 40\n",
    "        get_into_comps = []\n",
    "        h=1\n",
    "        while h<b:\n",
    "            ############ Get the name of the companies in the research result #######################\n",
    "            a=str(h)\n",
    "            get_into_comp = driver.find_element_by_xpath('/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/discover/page-layout/div/div/div[2]/section[2]/results/div/div/div[3]/sheet-grid/div/div/grid-body/div/grid-row['+a+']'+'/grid-cell[2]/div/field-formatter/identifier-formatter/a')\n",
    "            get_into_comps.append(get_into_comp)\n",
    "            h=h+1\n",
    "            ratios = []\n",
    "        for get_into_comp in get_into_comps:\n",
    "            ############### check which name is the closest of the one entered in the search bar #################\n",
    "            ratios.append(SequenceMatcher(None, companies[i], get_into_comp.text).ratio())\n",
    "        index_max = np.argmax(ratios)\n",
    "        ################ Click on the link associated with the company whose name has the highest similarity ######\n",
    "        get_into_comps[index_max].click()\n",
    "    else: #### If there is only one page (less than 40 results but more than one: we repeat the same process)\n",
    "        nb = nb_result[1].text.split(' res')[0]\n",
    "        b = int(nb)\n",
    "        if b>1:\n",
    "            get_into_comps = []\n",
    "            h=1\n",
    "            while h<=b:\n",
    "                a=str(h)\n",
    "                get_into_comp = driver.find_element_by_xpath('/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/discover/page-layout/div/div/div[2]/section[2]/results/div/div/div[3]/sheet-grid/div/div/grid-body/div/grid-row['+a+']'+'/grid-cell[2]/div/field-formatter/identifier-formatter/a')\n",
    "                get_into_comps.append(get_into_comp)\n",
    "                h=h+1\n",
    "            ratios = []\n",
    "            for get_into_comp in get_into_comps:\n",
    "                ratios.append(SequenceMatcher(None, companies[i], get_into_comp.text).ratio())\n",
    "            index_max = np.argmax(ratios)\n",
    "            get_into_comps[index_max].click()\n",
    "        else: ################################# There is only one company ##############\n",
    "            get_into_comp = driver.find_element_by_xpath('/html/body/chrome/div/mat-sidenav-container/mat-sidenav-content/div/discover/page-layout/div/div/div[2]/section[2]/results/div/div/div[3]/sheet-grid/div/div/grid-body/div/grid-row[1]/grid-cell[2]/div/field-formatter/identifier-formatter/a')\n",
    "            get_into_comp.click()\n",
    "            \n",
    "            \n",
    "            ##############################################################################\n",
    "            ########## End Get into company's profile ####################################\n",
    "            ##############################################################################\n",
    "            \n",
    "            \n",
    "            ##############################################################################\n",
    "            ########## Start searching if investment were made or not ####################\n",
    "            ##############################################################################\n",
    "    \n",
    "    sleep(randint(2,4))\n",
    "    get_status = driver.find_elements_by_xpath(\"//span[@class='component--field-formatter field-type-enum ng-star-inserted']\")\n",
    "    status = get_status[1].text.strip()\n",
    "    clickables = driver.find_elements_by_class_name('ng-star-inserted')\n",
    "    sleep(randint(2,4))\n",
    "    ok_clickable_funding =[]\n",
    "    for clickable in clickables:\n",
    "        if clickable.text.strip()=='Total Funding Amount':\n",
    "            ok_clickable_funding.append(clickable)\n",
    "    if len(ok_clickable_funding)==0: ## Non link related to funding were found --> create an empty dataset ###\n",
    "        df_comp = pd.DataFrame(columns=['Announced Date', 'Transaction Name', 'Number of Investors', 'Money Raised', 'Lead Investors'])\n",
    "        df_comp = df_comp.append({'Announced Date': 'Dec 2, 2030', 'Transaction Name': 'none', 'Number of Investors': 0, 'Money Raised': '$0', 'Lead Investors': 'none'}, ignore_index=True)\n",
    "        ok_clickable_investors = []\n",
    "        for clickable in clickables:\n",
    "            if clickable.text.strip()=='Number of Investors':\n",
    "                ok_clickable_investors.append(clickable)\n",
    "        if len(ok_clickable_investors) == 0: ## No link related to investors were found --> create an empty dataframe\n",
    "            df_investors = pd.DataFrame(columns=['Investor Name', 'Lead Investor', 'Funding Round', 'Partners'])\n",
    "            df_investors = df_investors.append({'Investor Name': 'none', 'Lead Investor': 'none', 'Funding Round': 'none', 'Partners': 'none'}, ignore_index=True)\n",
    "        else : ### A link to investors were found --> get in\n",
    "            ok_clickable_investors[0].click()\n",
    "            sleep(randint(5,8))\n",
    "            page_html = driver.page_source ## Charge the source code\n",
    "            df_list = pd.read_html(page_html) ## Take a list of tables\n",
    "            df_investors = df_list[1] ## Select the table associated with investors \n",
    "            \n",
    "            ################################################################################\n",
    "            ############# INVESTMENTS WERE MADE ############################################\n",
    "            ################################################################################\n",
    "    else:\n",
    "        ok_clickable_funding[0].click() # click on the link associated to investments\n",
    "        sleep(randint(5,8))\n",
    "        page_html = driver.page_source\n",
    "        checking_list_df = pd.read_html(page_html) \n",
    "        print(len(checking_list_df))\n",
    "        #####################################################################################\n",
    "        ## The len of the number of tables give information on which info are available, ##\n",
    "        ## The first one is related to investment received, the second one to investors, ##\n",
    "        ## the third to investment made, the forth to acquisition made ######################\n",
    "        #####################################################################################\n",
    "        \n",
    "        if len(checking_list_df)>2: ## We might have data abount acquisition and investments made\n",
    "            print(companies[i])\n",
    "            titles = driver.find_elements_by_class_name('section-title')\n",
    "            acquisitions = []\n",
    "            for title in titles:\n",
    "                if title.text.strip() =='Acquisitions':\n",
    "                    acquisitions.append(title.text.strip())\n",
    "            if len(acquisitions)>0: ## If acquisition is written somewhere on the page\n",
    "                        df_acquisition = checking_list_df[-1] ## The df is the last table given by the function pd.read_html\n",
    "                        buyer = [companies[i]]*len(df_acquisition)\n",
    "                        df_acquisition['Buyer'] = buyer\n",
    "                        list_acquisitions.append(df_acquisition)\n",
    "                ######################\n",
    "                        df_investments_made = checking_list_df[-2]\n",
    "                        comp_name_investing = [companies[i]]*len(df_investments_made)\n",
    "                        df_investments_made['Investing_company'] = comp_name_investing\n",
    "                        list_df_investments_made.append(df_investments_made)\n",
    "            else: ## If acquisition is not present on the page\n",
    "                print('else was taken into account')\n",
    "                df_investments_made = checking_list_df[2] # The investment made is the third table read by the function\n",
    "                comp_name_investing = [companies[i]]*len(df_investments_made)\n",
    "                df_investments_made['Investing_company'] = comp_name_investing\n",
    "                list_df_investments_made.append(df_investments_made)\n",
    "                \n",
    "                ###################################################################################################\n",
    "                ## Check the lenth of the table to know if we must click to unwrap them to charge the whole data ##\n",
    "                ###################################################################################################\n",
    "                \n",
    "        clickables2 = driver.find_elements_by_class_name('mat-button-wrapper')\n",
    "        ok_clickable2 =[]\n",
    "        for clickable in clickables2:\n",
    "            if clickable.text.strip()=='VIEW ALL':\n",
    "                ok_clickable2.append(clickable)\n",
    "        if len(ok_clickable2)==0: # All table are full length no need to unwrap\n",
    "            df_list = pd.read_html(page_html)\n",
    "            ###########################################################################\n",
    "            ## Check if we have investment, and/or investors ##########################\n",
    "            ##########################################################################\n",
    "            if len(df_list)==1:\n",
    "                df_comp = df_list[0]\n",
    "                df_investors = pd.DataFrame(columns=['Investor Name', 'Lead Investor', 'Funding Round', 'Partners'])\n",
    "                df_investors = df_investors.append({'Investor Name': 'none', 'Lead Investor': 'none', 'Funding Round': 'none', 'Partners': 'none'}, ignore_index=True)\n",
    "            elif len(df_list)==2:\n",
    "                df_comp = df_list[0]\n",
    "                df_investors = df_list[1]\n",
    "            elif len(df_list)>2:\n",
    "                df_comp = df_list[0]\n",
    "                df_investors = df_list[1]\n",
    "                \n",
    "        elif len(ok_clickable2)==2 : ## Two tables are not full length and need to be unwrapped\n",
    "            \n",
    "            ######## Start unwrap the list and charge the data#########################\n",
    "            ok_clickable2[0].click()\n",
    "            sleep(randint(2,3))\n",
    "            page_html2 = driver.page_source\n",
    "            df_list2 = pd.read_html(page_html2)\n",
    "            df_comp = df_list2[0]\n",
    "            ###### Stop unwrap the list and charge the data #########################\n",
    "            driver.back()\n",
    "            sleep(randint(2,3))\n",
    "            page_html3 = driver.page_source\n",
    "            \n",
    "            ######## Start unwrap the list and charge the second data #########################\n",
    "            clickables3 = driver.find_elements_by_class_name('mat-button-wrapper')\n",
    "            ok_clickables3 =[]\n",
    "            for clickable in clickables3:\n",
    "                if clickable.text.strip()=='VIEW ALL':\n",
    "                    ok_clickables3.append(clickable)\n",
    "            ok_clickables3[1].click()\n",
    "            sleep(randint(2,3))\n",
    "            page_html4 = driver.page_source\n",
    "            df_list4 = pd.read_html(page_html4)\n",
    "            df_investors = df_list4[0]\n",
    "            ######## Stop unwrap the list and charge the second data #########################\n",
    "            driver.back()\n",
    "            \n",
    "        elif len(ok_clickable2)==1 : # only one of the tables need to be unwrapped\n",
    "            ok_clickable2[0].click()\n",
    "            sleep(randint(2,3))\n",
    "            page_html = driver.page_source\n",
    "            header = driver.find_elements_by_class_name('section-title')\n",
    "            if (header[0].text.strip())=='Funding Rounds': ### Check which one it is that was unwrapped (investment vs investors)\n",
    "                df_list = pd.read_html(page_html)\n",
    "                df_comp = df_list[0]\n",
    "                driver.back()\n",
    "                sleep(randint(2,3))\n",
    "                page_html = driver.page_source\n",
    "                df_list = pd.read_html(page_html)\n",
    "                df_investors = df_list[1]\n",
    "            elif (header[0].text.strip())=='Investors':\n",
    "                df_list = pd.read_html(page_html)\n",
    "                df_investors = df_list[0]\n",
    "                driver.back()\n",
    "                sleep(randint(2,3))\n",
    "                page_html = driver.page_source\n",
    "                df_list = pd.read_html(page_html)\n",
    "                df_comp = df_list[0]\n",
    "                \n",
    "        ##########################################################################################\n",
    "        ################ Stop grabing data #######################################################\n",
    "        ##########################################################################################\n",
    "        \n",
    "        ###########################################################################################\n",
    "        #################### Compile and append into empty lists ##################################\n",
    "        ###########################################################################################\n",
    "        \n",
    "        \n",
    "    df_comp = formating_dates(df_comp) #### Formate dates\n",
    "    df_comp = clean_up_dataset(df_comp) ### turn data from string and currency to integers\n",
    "    \n",
    "    \n",
    "    comp_name = [companies[i]]*len(df_comp)\n",
    "    comp_country = [country_agg[i]]*len(df_comp)\n",
    "    comp_subsector = [Label[i]]*len(df_comp)\n",
    "    comp_status = [status]*len(df_comp)\n",
    "    df_comp['Comp_name'] = comp_name\n",
    "    df_comp['Comp_country'] = comp_country\n",
    "    df_comp['Comp_subsector'] = comp_subsector\n",
    "    df_comp['Comp_status'] = comp_status\n",
    "    list_df_comp.append(df_comp)\n",
    "    list_df_investors.append(df_investors)\n",
    "    sleep(randint(4,5))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append the datasets that were stored in lists into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For investments\n",
    "data_comp = pd.concat(list_df_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to visualize\n",
    "#data_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For investors\n",
    "df_investors = pd.concat(list_df_investors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate comp name and investments\n",
    "all_in = df_investors['Funding Round'].tolist()\n",
    "\n",
    "funding_round = []\n",
    "company = []\n",
    "for item in all_in:\n",
    "    if ' - ' in item:\n",
    "        funding = item.split(' - ',1)[0]\n",
    "        funding_round.append(funding)\n",
    "        comp = item.split(' - ',1)[1]\n",
    "        company.append(comp)\n",
    "    else:\n",
    "        funding_round.append('none')\n",
    "        company.append('none')\n",
    "df_investors['Round'] = funding_round\n",
    "df_investors['Company_name'] = company\n",
    "\n",
    "##########################################################################################\n",
    "##### Add the country of the company the investors invested in by using data_comp#########\n",
    "##########################################################################################\n",
    "\n",
    "#### Create a subset of data_comp to work with by droping the duplicate hence  ############\n",
    "#### the companies are unique and associated to their country #############################\n",
    "df_companies_work = data_comp[['Comp_name', 'Comp_country']]\n",
    "df_companies_work = df_companies_work.drop_duplicates()\n",
    "\n",
    "####### Create two list that we will match from df_investor we take comp name, also from data_comp + the country from data comp#\n",
    "\n",
    "companies_inv = df_investors['Company_name'].tolist()\n",
    "comp_name = df_companies_work['Comp_name'].tolist()\n",
    "comp_country = df_companies_work['Comp_country'].tolist()\n",
    "\n",
    "Comp_country = []\n",
    "for comp in companies_inv: # Takes each comp name in the investor dataset\n",
    "    if comp in comp_name: # If the name is found in the data_comp dataset\n",
    "        ind = (comp_name.index(comp)) # --> check the index\n",
    "        country = comp_country[ind]# --> Find the country associated to this index into country name from data_comp\n",
    "        Comp_country.append(country) # --> append it to list\n",
    "    else:\n",
    "        country = 'Unknown'\n",
    "        Comp_country.append(country)\n",
    "        \n",
    "df_investors['Comp_country'] = Comp_country ## Add it to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_invest.to_excel('C:/yourway/data_investors.xlsx', index=None, header= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_invest_made = pd.concat(list_df_investments_made)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_invest_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_acquisition = pd.concat(list_acquisitions)\n",
    "#data_acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individuating the funding round from company name for investments data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_name_round = data_comp['Transaction Name'].tolist()\n",
    "funding_round = []\n",
    "for item in sep_name_round:\n",
    "    if ' - ' in item:\n",
    "        funding = item.split(' - ',1)[0]\n",
    "        funding_round.append(funding)\n",
    "    else:\n",
    "        funding_round.append('none')\n",
    "data_comp['Round'] = funding_round\n",
    "data_comp.drop(['Transaction Name'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking which kind of funding there was and aggregate into highr classes to represent early risky investments - later stage investments - other kind of investments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp.Round.unique()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For tractability matter it is usefull to group the types of funding into bigger categories:\n",
    "Early stage investments will regroup under the Seed Round denomination both :\n",
    "    Seed Round\n",
    "    Funding round\n",
    "    Pre seed round\n",
    "    Convertible notes (although they are different in nature as they are a title of debt it is used in early stage financement    and easily convertible into title of property)\n",
    "    Grant\n",
    "    Angel\n",
    "    Product crowdfunding\n",
    "    Initial Coin Offering\n",
    "    Non equity assistance\n",
    "    \n",
    "Middle stage investments:\n",
    "    Serie A, Serie B, Venture Round (will be assumed to be equivalent to serie A)\n",
    "    \n",
    "Later stage investment:\n",
    "    Serie C, D, E, F, G, J, H, I, Debt financing\n",
    "    \n",
    "Public offering\n",
    "    Secondary Market, Post-IPO Equity, Post-IPO Debt, Post-IPO Secondary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Round = df_companies_clean.Round.tolist()\n",
    "agg_round = []\n",
    "for item in Round:\n",
    "    if item =='Seed Round':\n",
    "        agg_round.append('Seed')\n",
    "    elif item == 'Series A':\n",
    "        agg_round.append('Serie A')\n",
    "    elif item == 'Funding Round':\n",
    "        agg_round.append('Unknown type')\n",
    "    elif item == 'Venture Round':\n",
    "        agg_round.append('Serie A')\n",
    "    elif item == 'Debt Financing':\n",
    "        agg_round.append('Debt Financing')\n",
    "    elif item == 'Pre Seed Round':\n",
    "        agg_round.append('Seed')\n",
    "    elif item == 'Grant':\n",
    "        agg_round.append('Grant')\n",
    "    elif item == 'Angel Round':\n",
    "        agg_round.append('Angel')\n",
    "    elif item == 'Non Equity Assistance':\n",
    "        agg_round.append('Other')\n",
    "    elif item == 'Convertible Note':\n",
    "        agg_round.append('Seed')\n",
    "    elif item == 'Series C':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series B':\n",
    "        agg_round.append('Serie B')\n",
    "    elif item == 'Corporate Round':\n",
    "        agg_round.append('Serie B')\n",
    "    elif item == 'Equity Crowdfunding':\n",
    "        agg_round.append('Other')\n",
    "    elif item == 'none':\n",
    "        agg_round.append('none')\n",
    "    elif item == 'Private Equity Round':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Secondary Market':\n",
    "        agg_round.append('IPO+')\n",
    "    elif item == 'Series J':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series I':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series H':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series G':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series F':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series E':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Series D':\n",
    "        agg_round.append('C+')\n",
    "    elif item == 'Post-IPO Equity':\n",
    "        agg_round.append('IPO+')\n",
    "    elif item == 'Post-IPO Debt':\n",
    "        agg_round.append('IPO+')\n",
    "    elif item == 'Post-IPO Secondary':\n",
    "        agg_round.append('IPO+')\n",
    "    elif item == 'Product Crowdfunding':\n",
    "        agg_round.append('Other')\n",
    "    elif item == 'Initial Coin Offering':\n",
    "        agg_round.append('Other')\n",
    "df_companies_clean['Agg_round'] = agg_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data\n",
    "data_comp.to_excel('C:/yourway/data_invest.xlsx', index=None, header= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create two new datasets : One that takes off companies where no investments where made, one that discard missing values (if the amount of investment is not known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard companies with no investments\n",
    "df_companies_clean = data_comp[data_comp['Money_clean']!='0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discard missing values\n",
    "df_comp_wmv = df_companies_clean[df_companies_clean['Money_clean']!='NaN']\n",
    "\n",
    "# Convert float to integers\n",
    "df_comp_wmv['Money_clean'] = df_comp_wmv['Money_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save datasets\n",
    "df_comp_wmv.to_excel('C:/your_path/data_private_investment_wmv.xlsx', index=False) ## Will be used to analyse the investments in quantity\n",
    "df_companies_clean.to_excel('C:/your_path/data_private_investment_mv.xlsx', index=False) ## Will be used to analyse the investments in number"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
